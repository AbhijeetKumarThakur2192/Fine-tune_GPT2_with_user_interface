Guide how to use fine-tune with user interface:

1) Install important modules like PyTorch, Transformers and Accelerate.
2) Clone this repository
3) Run fine-tune.py
4) Now type 1 to continue fine-tune or type 2 to exit.
5) Enter model name like gpt2, gpt2-medium, gpt2-large, gpt2-xl and if you have already gpt2 model file in the folder give its path (Remember the given code is specially made for fine-tune GPT2 model don't use other model otherwise it show error!)
6) Enter data.txt file path (Hint: Type the path of your data.txt file. If not available you can use our sample-data.txt)
7) Enter output file path (Hint: Type the path or folder where you wanted to save your fine-tuned model)
8) Enter number of batch size like 2, 4, 6, 8, 10, 12 etc (Hint: If you have 8gb ram try 6, if you have 16gb ram try 14)
9) Enter number of epochs like 10, 20, 30, 40, 50 etc (Hint: Best number of epochs depend on how long your data. Excessive epochs cause overfitting. My recommend number is 50)
10) Enter learning rate I prefer 1e-4 or 5e-5 also check on internet for better understanding.
11) Enter number of save steps like 1000, 2000, 3000, 4000, 5000 etc (Hint: Save steps can help to secure your fine-tune model during fine-tune. Recommend number 5000)
12) Now it takes some time to finish fine-tune process.
13) After when fine-tune done you can use your fine-tuned model.
14) To use your fine tune model just type chat.py
15) Now enter model path where you have fine-tuned model than provide length of response like 50, 100, 250, 500 etc (Remember high number can take long time to generate response)

Common Queries:

Q. How much time it take?
A. It depend how long your data and what information you filled on it.

Q. Can I again fine-tune my gpt2 prefine-tuned model?
A. Yes you can refine-tune to increase their understanding and knowledge. 

Q. How I refine-tune gpt2 model?
A. Just simply type your fine-tuned model path when it ask for model name.

Q. Can I fine-tune other text generation model using this code?
A. Not recommend because this code made only for gpt2 model but if you want to fine-tune other model you can try as an experimental purpose (You may get error!)

Q. What data structure I provide to fine-tune model?
A. The best structure is qna pair. You can check how you can do that on sample-data.txt but if you give any other data structure it may not work properly.

Q. Is your provided fine-tune code advance?
A. Once again I say big thanks to [Dr. Sreenivas Bhattiprolu] DigitalSreenI for providing code publicly without restrictions and the answer is nope in this code it just simple structure that can help to fine-tune if you don't understand coding or you want to do in fast way but you can implement more code to make more powerful fine-tune code. 

Q. I have data in pdf formate what I do?
A. This code is totally made for txt format but if you have data in format of pdf you can try to convert it into txt format otherwise add additional code for using pdf file format.

Q. What benefit I get to fine-tune gpt2 model?
A. You can use it as for study material, problem solving, for fun, for education purpose. [PLEASE REMEMBER DON'T MISUSE THIS CODE. USE THIS CODE FOR ONLY ETHICAL AND EDUCATIONAL PURPOSE]

Q. Why I waste my time to fine-tune gpt2 model with qna because if I know what answer of the question why I ask to my fine-tune model?
A. Fine-tuning a model like GPT-2 for Q&A tasks helps automate the process of generating accurate responses based on questions, especially when dealing with a large volume of inquiries or when the answers aren't readily available to you. It streamlines the process and can save time in providing accurate information without manually searching for each answer. [This answer is generated by my fine-tune gpt2-medium model.This process has truly showcased its effectiveness and potential.]

Q. What is the best gpt2 version?
A. Well the best of gpt2 is depend on your task and resource like if you have powerful resources so you can try gpt2-large or gpt2-xl but if you have limited resources so you can try gpt2 or gpt2-medium. 

Q. Last question did you use gpt2 model?
A. Yes I also use gpt2-medium model because it is small and powerful.